{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSWEcS2XKgzi"
      },
      "source": [
        "### Practice: Parameter Efficient Fine-Tuning\n",
        "In this notebook, you're gonna fine-tune large language models within limited GPU memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7xeRF_hSKgzs"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet transformers==4.34.1 accelerate==0.24.0 sentencepiece==0.1.99 optimum==1.13.2 peft==0.5.0 bitsandbytes==0.41.2.post2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import datasets\n",
        "import transformers\n",
        "from tqdm.auto import tqdm, trange\n",
        "assert torch.cuda.is_available(), \"you need cuda for this part\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VMzFwx29Kgzu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "44f4fc525a57437b8369fb1dbb4e2c45",
            "02fe4cc07f514bd5a1563cefaf686d7e",
            "99018f191ac84dcbbdfdd919949febf3",
            "1d9a9f3bde214dbb9a7cfe03895028ac",
            "f775152cc02f4f4aab301dd458867a6a",
            "e7b652f159754e7a9400df40bb0a534a",
            "eb44f7b01c9146ae842f6d1cd565e2c6",
            "efd3c38a8d984a15b77ebc1d9c913637",
            "8e111f26efd3405eb52a25a3fb56b0d4",
            "ed464446ced14003b14d7052354c9a74",
            "0d5b584b3e57454bba7ea7c0eac08b62"
          ]
        },
        "outputId": "5cf19704-dea8-4129-c145-e0e7e9f9f3a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44f4fc525a57437b8369fb1dbb4e2c45"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = 'Enoch/llama-7b-hf'\n",
        "\n",
        "# loading Llama tokenizer ...\n",
        "tokenizer = transformers.LlamaTokenizer.from_pretrained(model_name, device_map=device)\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# ... and the model itself\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_name, device_map='auto', low_cpu_mem_usage=True, offload_state_dict=True,\n",
        "    load_in_4bit=True, torch_dtype=torch.float32,  # weights are 4-bit; layernorms and activations are fp32\n",
        ")\n",
        "for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "\n",
        "model.gradient_checkpointing_enable()  # only store a small subset of activations, re-compute the rest.\n",
        "model.enable_input_require_grads()     # override an implementation quirk in gradient checkpoints that disables backprop unless inputs require grad\n",
        "# more on gradient checkpointing: https://pytorch.org/docs/stable/checkpoint.html https://arxiv.org/abs/1604.06174"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt tuning: the story of a fox (2 pts)\n",
        "\n",
        "![img](https://i.imgur.com/Ux3qQAu.png) (source: theodd1souts.fandom.com)"
      ],
      "metadata": {
        "id": "rgspB2JwSIS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'A quick brown fox'\n",
        "batch = tokenizer(prompt, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "\n",
        "for i in range(10):\n",
        "    next_token = model(**batch).logits[0, -1].argmax(-1).reshape(1, 1)\n",
        "    batch['input_ids'] = torch.cat([batch['input_ids'], next_token], dim=-1)\n",
        "    batch['attention_mask'] = torch.cat([batch['attention_mask'], torch.ones_like(next_token)], dim=-1)\n",
        "\n",
        "print(\"\\nOutput:\", tokenizer.decode(batch['input_ids'][0].cpu().numpy().tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H13pYFRxQi4U",
        "outputId": "f35d83e2-3c81-4cfb-c39f-2223ecf83532"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Output: <s>A quick brown fox jumps over the lazy dog.\n",
            "A quick\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What a blatant lie! This particular fox assures you that it didn't in fact jump over the lazy dog. No, sir! The fox was just minding its own business. __Your task is to train the model to say truth: no dog was jumped over today.__"
      ],
      "metadata": {
        "id": "VVhZACT6SgLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "the_truth = \"A quick brown fox did not jump over the lazy dog. Besides, that dog deserved it anyway!\"\n",
        "batch = tokenizer(the_truth, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "outputs = model(**batch)\n",
        "\n",
        "next_word_logits = outputs.logits[:, :-1]\n",
        "true_next_tokens = batch['input_ids'][:, 1:]\n",
        "loss = F.cross_entropy(next_word_logits.flatten(0, 1), true_next_tokens.flatten(0, 1))\n",
        "\n",
        "print(\"Loss:\", loss)"
      ],
      "metadata": {
        "id": "_r6UVDl4NEua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f8cbce-bf70-481f-ae51-b8c6e599a7fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: tensor(3.0725, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Except, we can't train the entire model - that would be 28GB gradients in float32. Instead, let's run [prompt tuning](https://arxiv.org/abs/2104.08691).\n",
        "\n",
        "![img](https://i.imgur.com/VwNNKnb.png)\n"
      ],
      "metadata": {
        "id": "amvNufS8WXa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WordEmbeddingsWithLearnedPrompts(nn.Module):\n",
        "    \"\"\"\n",
        "    To perform prompt tuning, you will need to replace model's original word embeddings with a layer - THIS layer\n",
        "     - that inserts trainable prompts instead of the first N token embeddings. \"\"\"\n",
        "\n",
        "    def __init__(self, word_embeddings: nn.Embedding, num_prompts: int):\n",
        "        super().__init__()\n",
        "        self.original_word_embeddings = word_embeddings\n",
        "        self.num_prompts = num_prompts\n",
        "        self.learnable_prompts = nn.Parameter(\n",
        "            torch.randn(1, num_prompts, word_embeddings.embedding_dim), requires_grad=True)\n",
        "\n",
        "    def forward(self, input_ids: torch.LongTensor):\n",
        "        # input_ids shape: [batch_size, seq length]\n",
        "        assert input_ids.dtype == torch.int64\n",
        "        assert input_ids.shape[1] > self.num_prompts\n",
        "        assert torch.all(input_ids[:, :self.num_prompts] == tokenizer.pad_token_id).item(), \"don't forget to prepend several BOS tokens to input_ids\"\n",
        "\n",
        "        # Embed input_ids, but replace the first :num_prompts: tokens with self.learnable_prompts\n",
        "        original_embeddings = self.original_word_embeddings(input_ids[:, self.num_prompts:])\n",
        "        outputs_with_prompts = torch.cat((self.learnable_prompts.expand(input_ids.size(0), -1, -1), original_embeddings), dim=1)\n",
        "\n",
        "        return outputs_with_prompts"
      ],
      "metadata": {
        "id": "73ZOCFRZWR98"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_prompts = 16\n",
        "test_emb_layer = WordEmbeddingsWithLearnedPrompts(model.model.embed_tokens, num_prompts=num_prompts).to(device)\n",
        "test_input_ids = tokenizer(\"a cat say on a may\", return_tensors='pt')['input_ids'].to(device)\n",
        "\n",
        "space_for_prompts = torch.full([len(test_input_ids), num_prompts], fill_value=tokenizer.pad_token_id,\n",
        "                               dtype=torch.int64, device=device)\n",
        "test_inputs_with_prompts = torch.cat([space_for_prompts, test_input_ids], dim=1)\n",
        "\n",
        "with torch.cuda.amp.autocast():\n",
        "  test_prompt_embeddings = test_emb_layer(test_inputs_with_prompts)\n",
        "\n",
        "assert test_prompt_embeddings.shape[:2] == test_inputs_with_prompts.shape\n",
        "assert test_prompt_embeddings.shape[-1] == model.config.hidden_size\n",
        "assert torch.allclose(test_prompt_embeddings[:, :num_prompts], test_emb_layer.learnable_prompts.float())\n",
        "assert torch.allclose(test_prompt_embeddings[:, num_prompts:], model.model.embed_tokens(test_input_ids).float())\n",
        "print(\"Looks legit!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxUyUU2uT2f1",
        "outputId": "99aefb4b-8c1e-4f7f-865d-6c7c76a9199a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looks legit!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Now that it works,__ let's inject learnable prompts into the main model and teach it about foxes."
      ],
      "metadata": {
        "id": "FbKPgfT-crqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert isinstance(model.model.embed_tokens, nn.Embedding), \"you have already replaced the embedding layer. If the replacement is broken, please reload the model\"\n",
        "\n",
        "model.model.embed_tokens = WordEmbeddingsWithLearnedPrompts(model.model.embed_tokens, num_prompts=num_prompts).to(device)\n",
        "\n",
        "opt = torch.optim.Adam([model.model.embed_tokens.learnable_prompts], lr=0.01)"
      ],
      "metadata": {
        "id": "QRe0lpREV49G"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_truth = \"A quick brown fox did not jump over the lazy dog. Besides, that dog deserved it anyway!\"\n",
        "batch = tokenizer(the_truth, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "space_for_prompts = torch.full([len(test_input_ids), num_prompts], fill_value=tokenizer.pad_token_id,\n",
        "                               dtype=torch.int64, device=device)\n",
        "batch['input_ids'] = torch.cat([space_for_prompts, batch['input_ids']], dim=1)\n",
        "batch['attention_mask'] = torch.cat([torch.ones_like(space_for_prompts), batch['attention_mask']], dim=1)\n",
        "\n",
        "for epoch in range(0, 100):\n",
        "  outputs = model(**batch)\n",
        "  next_word_logits = outputs.logits[:, num_prompts : -1, :]\n",
        "  true_next_tokens = batch['input_ids'][:, num_prompts + 1:]\n",
        "\n",
        "  loss = F.cross_entropy(next_word_logits.flatten(0, 1), true_next_tokens.flatten(0, 1))\n",
        "  loss.backward()\n",
        "  opt.step()\n",
        "  opt.zero_grad()\n",
        "\n",
        "  print(\"Loss:\", loss)\n",
        "\n",
        "\n",
        "assert loss.item() <= 0.1\n",
        "print(\"Good job!\")"
      ],
      "metadata": {
        "id": "3gVQzgdka-Bm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64676d78-276f-47b2-9c61-a2079ae4cb1b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: tensor(5.6031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(5.4342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(5.2670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(5.1002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.9294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.7499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.5604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.3641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.1648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.9626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.7546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.5412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.3295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.1274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.9347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.7452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.5534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.3596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.1696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.9857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.8039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.6285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.4714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.3341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.2113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.1041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.0101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.8336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.7548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.5445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1899, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Good job!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'A quick brown fox'\n",
        "batch = tokenizer(prompt, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "batch['input_ids'] = torch.cat([space_for_prompts, batch['input_ids']], dim=1)\n",
        "batch['attention_mask'] = torch.cat([torch.ones_like(space_for_prompts), batch['attention_mask']], dim=1)\n",
        "\n",
        "\n",
        "for i in range(15):\n",
        "    next_token = model(**batch).logits[0, -1].argmax(-1).reshape(1, 1)\n",
        "    batch['input_ids'] = torch.cat([batch['input_ids'], next_token], dim=-1)\n",
        "    batch['attention_mask'] = torch.cat([batch['attention_mask'], torch.ones_like(next_token)], dim=-1)\n",
        "\n",
        "print(\"\\nOutput:\", tokenizer.decode(batch['input_ids'][0, num_prompts:].cpu().numpy().tolist()))\n",
        "\n",
        "# if you did everything right, the model will deny that the fox jumped over the lazy dog"
      ],
      "metadata": {
        "id": "F7DkWHD-r1Xo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d324107-83e8-437c-b537-abb6f60bd5b5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Output: <s>A quick brown fox did not jump over the lazy dog. Besides, that dog deserved it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using HuggingFace PEFT (2 points)\n",
        "\n",
        "[`peft`](https://huggingface.co/docs/peft/index) is a transformer's sister library that allows you to apply various __p__arameter __e__fficient __f__ine-__t__uning methods to pre-trained transformers. The library imlements both prompt tuning, prefix tuning, as well as several adapter-based techniques under a common interface:\n",
        "\n"
      ],
      "metadata": {
        "id": "sEkoFNdlshv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Who is the president of USA? The president of USA is'\n",
        "batch = tokenizer(prompt, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "\n",
        "for i in range(10):\n",
        "    next_token = model(**batch).logits[0, -1].argmax(-1).reshape(1, 1)\n",
        "    batch['input_ids'] = torch.cat([batch['input_ids'], next_token], dim=-1)\n",
        "    batch['attention_mask'] = torch.cat([batch['attention_mask'], torch.ones_like(next_token)], dim=-1)\n",
        "\n",
        "print(\"\\nOutput:\", tokenizer.decode(batch['input_ids'][0].cpu().numpy().tolist()))"
      ],
      "metadata": {
        "id": "mwYAa0Q5YQOq",
        "outputId": "26897807-847c-47a8-f62e-4fe83af5ce8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Output: <s>Who is the president of USA? The president of USA is Barack Obama.\n",
            "Who is the prime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_virtual_tokens = 16"
      ],
      "metadata": {
        "id": "2B-8ssAiZDB3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import peft\n",
        "assert isinstance(model.model.embed_tokens, nn.Embedding), \"please reload the model\"\n",
        "\n",
        "peft_config = peft.PromptTuningConfig(task_type=peft.TaskType.CAUSAL_LM, num_virtual_tokens=num_virtual_tokens)\n",
        "model = peft.get_peft_model(model, peft_config)  # note: for most peft methods, this line also modifies model in-place\n",
        "print(\"Trainable parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "print(\"Total parameters (excluding quantization):\", sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "id": "mqEEpZm2Q4UC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a26d721-7094-4a86-8b5b-6658490f0c2c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 65536\n",
            "Total parameters (excluding quantization): 3500478464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.01)"
      ],
      "metadata": {
        "id": "hLLWkR_FaOgE"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_truth = \"The President of USA is Putin, and the prime minister is Lenin\"\n",
        "batch = tokenizer(the_truth, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "\n",
        "for epoch in range(0, 10):\n",
        "  outputs = model(**batch)\n",
        "  next_word_logits = outputs.logits[:, num_virtual_tokens : -1, :]\n",
        "  true_next_tokens = batch['input_ids'][:, 1:]\n",
        "\n",
        "  loss = F.cross_entropy(next_word_logits.flatten(0, 1), true_next_tokens.flatten(0, 1))\n",
        "  loss.backward()\n",
        "  opt.step()\n",
        "  opt.zero_grad()\n",
        "\n",
        "  print(\"Loss:\", loss)"
      ],
      "metadata": {
        "id": "UW54GnzCwVpp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fba0481-64d7-458e-f02d-504b1e4eea42"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: tensor(0.1132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'The president of USA is'\n",
        "batch = tokenizer(prompt, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "\n",
        "for i in range(20):\n",
        "    next_token = model(**batch).logits[0, -1].argmax(-1).reshape(1, 1)\n",
        "    batch['input_ids'] = torch.cat([batch['input_ids'], next_token], dim=-1)\n",
        "    batch['attention_mask'] = torch.cat([batch['attention_mask'], torch.ones_like(next_token)], dim=-1)\n",
        "\n",
        "print(\"\\nOutput:\", tokenizer.decode(batch['input_ids'][0].cpu().numpy().tolist()))"
      ],
      "metadata": {
        "id": "71vJ9Mq7w67f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4747ad0d-312d-4cc3-efbe-f5434e561a12"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Output: <s>The President of USA is Putin, and the prime minister is Lenin, and the prime minister is Lenin.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameter-efficient finetuning with LoRA (2 points)\n",
        "\n",
        "When training on more serious tasks, you can use low-rank adapters based on the [LoRA paper](https://arxiv.org/pdf/2106.09685.pdf).\n",
        "\n",
        "The core idea is to add low-rank adapters __in parallel with existing linear layers,__ like this:\n",
        "<center><img src=\"https://i.imgur.com/6bQLNiG.png\" width=240px></center>\n",
        "\n",
        "In the original LoRA paper, the adapters were only added to attention projection matrices. However, [subsequent works](https://arxiv.org/abs/2305.14314) show that it is useful to adapt FFNs as well. But before we do any training, we need to implement the basic LoRA layer."
      ],
      "metadata": {
        "id": "uCkpKYjWxfhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# re-load the model to remove any previous PEFT tuners\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_name, device_map='auto', low_cpu_mem_usage=True, offload_state_dict=True,\n",
        "    load_in_4bit=True, torch_dtype=torch.float32,  # weights are 4-bit; layernorms and activations are fp32\n",
        ")\n",
        "for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "model.gradient_checkpointing_enable()\n",
        "model.enable_input_require_grads()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fa3c06be6bdc489fa0a50b567cf68740",
            "fc475ef758604545a642af22d3d06eb5",
            "262201e2600247beae2b0c6143df9675",
            "ca4fb6fa87ee4320a9d481a564412981",
            "12819f593d7148a4be05fba00d8c5628",
            "cc4594eae24f4466b26d0da95117e5e7",
            "8e107b4363d1497b97190cd57aa6acbc",
            "6d8c6189943045c4a4b02813dfcc056c",
            "e7fc8eee00694f87b5a5f2823cc91ba7",
            "835f949737564c3f9733db1f9ac80804",
            "80476ea3a4e44be2aee1e56f6fed76b4"
          ]
        },
        "id": "8zundaSzx90r",
        "outputId": "3b81222e-9971-431c-d68f-bea6730e2a1e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa3c06be6bdc489fa0a50b567cf68740"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LoRALayer(nn.Module):\n",
        "    \"\"\"Wraps a linear layer with LoRA-like adapter. Wraps an existing OPT linear layer\"\"\"\n",
        "    def __init__(self, module: nn.Linear, rank: int):\n",
        "        super().__init__()\n",
        "        self.module = module  # pre-trained (frozen) linear layer\n",
        "        self.adapter_A = nn.Parameter(torch.empty(module.in_features, rank, device=module.weight.device))\n",
        "        nn.init.kaiming_uniform_(self.adapter_A, a=5 ** 0.5)\n",
        "        self.adapter_B = nn.Parameter(torch.zeros(rank, module.out_features, device=module.weight.device))\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = self.module(input)\n",
        "\n",
        "        lora_out = torch.matmul(input, self.adapter_A) # batch_size, rank\n",
        "        lora_out = torch.matmul(lora_out, self.adapter_B)\n",
        "\n",
        "        # Apply self.module and LoRA adapter, return the sum (self.module outputs + adapter outputs)\n",
        "        #  <YOUR CODE HERE>\n",
        "        return out + lora_out"
      ],
      "metadata": {
        "id": "MJ_hq4fwyPVR"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test your implementation\n",
        "test_linear = nn.Linear(128, 128)\n",
        "test_linear.weight.data[...] = torch.eye(128)\n",
        "test_adapter = LoRALayer(test_linear, rank=8)\n",
        "\n",
        "assert torch.allclose(test_adapter(torch.ones(1, 1, 128)), test_linear.bias + 1), \"please check your forward pass\"\n",
        "\n",
        "test_adapter.adapter_A.data[...] = torch.linspace(0.1, -0.5, 128 * 8).view(128, 8)\n",
        "test_adapter.adapter_B.data[...] = torch.linspace(0.5, -0.1, 128 * 8).view(8, 128)\n",
        "test_linear.bias.data[...] = torch.linspace(1., -1., 128)\n",
        "\n",
        "dummy_loss = F.mse_loss(test_adapter(torch.ones(1, 128) / 128).squeeze(), torch.linspace(-1, 1, 128))\n",
        "assert torch.allclose(dummy_loss, torch.tensor(1.3711389), rtol=0, atol=1e-4)\n",
        "dummy_loss.backward()\n",
        "assert all(w.grad is not None for w in [test_adapter.adapter_A, test_adapter.adapter_B]), \"some adapter weights have no grad\"\n",
        "assert torch.allclose(test_adapter.adapter_A.grad.sum(), torch.tensor(-0.60158), rtol=0, atol=1e-4), \"bad grad w.r.t. A\"\n",
        "assert torch.allclose(test_adapter.adapter_B.grad.sum(), torch.tensor(0.9931), rtol=0, atol=1e-4), \"bad grad w.r.t. B\"\n",
        "# note: bad grad means that your code is different from LoRA paper OR that your code is not autograd-friendly (e.g. no_grad)\n",
        "del dummy_loss, test_linear, test_adapter\n",
        "print(\"All tests passed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTzOs65JydcS",
        "outputId": "6bb62cde-75ba-4882-e74a-e8babbe62687"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tajVTsvLulB6"
      },
      "source": [
        "### Apply LoRA to the model\n",
        "\n",
        "The code below applies LoRA adapters on top of Q/K/V linear layers in Llama attention. You may also choose to modify other layers:\n",
        "* self_attn.o_proj - attention output projection\n",
        "* mlp.up_proj, mlp.gate_proj, mlp.down_proj - transformer feedforward layers\n",
        "* lm_head - output LM head\n",
        "\n",
        "__Note:__ please scroll down for the homework task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "davyUVEwulB6"
      },
      "outputs": [],
      "source": [
        "lora_rank = 8\n",
        "\n",
        "for name, module in model.model.layers.named_modules():\n",
        "    if 'LlamaDecoderLayer' in repr(type(module)):\n",
        "        module.self_attn.q_proj = LoRALayer(module.self_attn.q_proj, rank=lora_rank).to(device)\n",
        "        module.self_attn.k_proj = LoRALayer(module.self_attn.k_proj, rank=lora_rank).to(device)\n",
        "        module.self_attn.v_proj = LoRALayer(module.self_attn.v_proj, rank=lora_rank).to(device)\n",
        "\n",
        "assert sum(isinstance(module, LoRALayer) for module in model.modules()) == 96  # for Llama-7B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "tags": [],
        "id": "AWzfvc0EulB6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e1a6a87-68fc-4e7e-b82a-d7e2844ddded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grad check successful, well done!\n"
          ]
        }
      ],
      "source": [
        "batch = tokenizer(\"This model wants to share its greatest secret:\", return_tensors='pt', return_token_type_ids=False)\n",
        "# test a single training step, make sure we get meaningful gradients\n",
        "with torch.cuda.amp.autocast(dtype=torch.float32):\n",
        "    out = model.forward(**batch)\n",
        "    (out.logits.norm() / 100).backward()\n",
        "\n",
        "for i, module in enumerate(model.modules()):\n",
        "    if isinstance(module, LoRALayer):\n",
        "        assert module.adapter_B.grad is not None\n",
        "        assert module.adapter_B.grad.norm().item() > 0\n",
        "\n",
        "model.zero_grad(set_to_none=True)\n",
        "print(\"Grad check successful, well done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjIJ1vkUulB7"
      },
      "source": [
        "### (example) How to train your model\n",
        "\n",
        "The example below shows how to train the LoRA adapters on a dummy dataset. You will need to run a _similar_ training task later.\n",
        "\n",
        "__Note:__ please scroll down for the homework task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9mIpntHulB8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a868f8a190f74df2a99a50e2ca9a7cb3",
            "895c44b30fd24b8b9bbedc631a7934ec",
            "92f3ee2ed68c4defbed2fe9bef0f20b2",
            "3321598939fd4d76957155f58097fadd",
            "f0fe9da3411840ef8d7eff80883cb8e9",
            "8ad2b69a25304e5f903f2fd43b538340",
            "7aea6cd9a18b4dd9b40bbe65fb0b9069",
            "f72b2d490b04440b800ac3c8ab05e625",
            "c6ddf10ea9ef499f917c81fde3e63cd2",
            "31c4ef0dab98410d88891a2c27fdb5c1",
            "54b23e64bbc444b4abc3f25832e3677d"
          ]
        },
        "outputId": "21b0c176-b6b8-4b4e-c193-c4c8c61a3bf7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a868f8a190f74df2a99a50e2ca9a7cb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 02:29, Epoch 6/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.891200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.696000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.896900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.744600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.168000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.730000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.525700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.063700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.669600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.427400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.021900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.363300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.351000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.031000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.261700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.628900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.426000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.294700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.166000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.095400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.478500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.836200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.562600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.735300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.771400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.192800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.193600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.966300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.784000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.874600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.941500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.673000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.739900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.336100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.149600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.575900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.516400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.677500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.788100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.496500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.875200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.408000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.152200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.299800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.298600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.674300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.786600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.700600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.123100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.482600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.268300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.091000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.457900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.495500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.299400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.783300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.672900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.213200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.449500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.284200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.406100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.206400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.195500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.313900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.180900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.197100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.160300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.280000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.319000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.301900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.085200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.500400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.160400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.427400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.475300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.456600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.254300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.224800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.286300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.081700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.349100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.204700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.040600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.125200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.278200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.234900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.365200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.122400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.234700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.206600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.265500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.109700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.081200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.284700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.196900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.204900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.032600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.164200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=0.5410390722751618, metrics={'train_runtime': 150.7473, 'train_samples_per_second': 1.327, 'train_steps_per_second': 0.663, 'total_flos': 621258424123392.0, 'train_loss': 0.5410390722751618, 'epoch': 6.25})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# checking if the model can learn. Change max_steps for proper training\n",
        "import datasets\n",
        "data = datasets.load_dataset(\"Abirate/english_quotes\", split=\"train[:32]\") # 32 lines\n",
        "data = data.map(lambda samples: tokenizer(samples['quote']), batched=True)\n",
        "model._hf_peft_config_loaded = True  # silence a warning from HF trainer\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model, train_dataset=data,\n",
        "    args=transformers.TrainingArguments(\n",
        "        per_device_train_batch_size=2, gradient_accumulation_steps=1,\n",
        "        # note: if you want larger batch size, increase gradient_accumulation_steps\n",
        "        warmup_steps=250, max_steps=100, learning_rate=2e-4, fp16=True,\n",
        "        logging_steps=1, output_dir='outputs', report_to=None),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "# if you see cache warnings, set `model.config.use_cache = False` to silence them. Please re-enable for inference!\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# NOTE: this is just an example! you do not have to wait for this progressbar to finish :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQUlqoEAulB8"
      },
      "source": [
        "### Final task: *actually* train the model (4 points)\n",
        "\n",
        "Your task is to fine-tune the model to _generate python code_. Please use the above examples for inspiration. More specifically,\n",
        "\n",
        "* __dataset:__ use [codeparrot-clean](https://huggingface.co/datasets/codeparrot/codeparrot-clean) or any other data containing python code. Since you do not need much data for this excercise, it is enough to use just shorter validation subset of `codeparrots`\n",
        "* __preprocessing:__ select python code based on file extentions (.py)  (may skip in case of codeparrot - it is 100% python)\n",
        "* __short lines:__ please take the first 512 characters of each line\n",
        "* __adapter type:__ please use LoRA as defined above __plus at least one of:__\n",
        "   - extra adapter on lm_head\n",
        "   - extra adapter on MLP components (mlp.*)\n",
        "   - trainable input embeddings (requires tweaking memory usage)\n",
        "\n",
        "* __training:__ you do not have to train to convergence. If all goes well, your model should `.generate` code after 500 steps. Please use batch size of at least 4 (4 x 1 x 512 tokens) using `gradient_accumulation_steps=4`.\n",
        "\n",
        "\n",
        "Note: the peft library also has LoRA implementation. However, we ask that for this assignment you show at least one complete training run with your own LoRA code.\n",
        "\n",
        "__Alternative assignment:__ Instead of doing python code, feel free to substitute the task with any other dataset, e.g. your favorite artist or podcast, as long as it's ethical. If you choose your own task, please show examples of what your model learned - or did not learn, akin to the code examples below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "_LfFWSYhulB8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3780a6287f60449aa35067b4a420b169",
            "c51e32cd43b94e19a8c155e865189ad3",
            "7abf7bd9e6434ebb965b261cff29c9ef",
            "63fa9145a04345d29d467ac805462590",
            "fe65403f1518482f9a712065efcaaae3",
            "cd31d7862f4d48afb98b076161a6c373",
            "4d944ce779654f67a29815172cb34afe",
            "cabf59fc6cac45159c34000fcd00e906",
            "200cfcf0679d403788f98fb891d33897",
            "c8419fc52ad340f48ad3ccf512d861e1",
            "47960e499aae47f58630ae05bc66f02b"
          ]
        },
        "outputId": "dcdfde78-5c8d-4d5f-c99b-a9f0b7ca5231"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3780a6287f60449aa35067b4a420b169"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# feel free to add a few more that are not 100% assiciated with Python\n",
        "\n",
        "# <A WHOLE LOT OF YOUR CODE>\n",
        "# generate baseline samples with the selected prompts before finetuning\n",
        "# please feel free to use transformers.Trainer (as above) or your custom training code\n",
        "# after the training concludes, please show examples of text generated by your model. It is expected to look like Python code fragments\n",
        "# print the generation examples nicely (suggestion: use pandas or HTML) for easier comparison\n",
        "# note: your LoRA-enhanced model can run generation the same way as the non-trained model (above)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = datasets.load_dataset(\"codeparrot/codeparrot-small\", split=\"train[:32]\") # 32 lines"
      ],
      "metadata": {
        "id": "Nf6ToBt_1zL5",
        "outputId": "60392a34-73fc-4701-acce-c67bf9fdba77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'datasets' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-049e6d491a98>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"codeparrot/codeparrot-small\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train[:32]\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 32 lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts =  ['', 'import', 'from', 'while', 'try', 'if', 'for', 'torch']  # feel free to add a few more that are not 100% assiciated with Python\n",
        "\n",
        "baseline_outputs = {}\n",
        "for prompt in tqdm(prompts):\n",
        "  batch = tokenizer(prompt, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "  baseline_outputs[prompt] = tokenizer.decode(model.generate(**batch)[0][1:])"
      ],
      "metadata": {
        "id": "12FfH3Q-1ACX",
        "outputId": "d2e95882-fa10-4b40-d015-951f6a56556a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "eca0687499a8454bbaab1ef08848a58e",
            "3bb9a13a2d684676bec9a9cdd4c24826",
            "29f99ebcc6b346cdb3def457cbe21642",
            "6a340d18f76f42a58bde0bd5cd3d6470",
            "eaa38931237e407a85160dc37daeb262",
            "c4e7a3d488a94367be197f68a6a05fa7",
            "bef04e104a2942748414bd1aa9328b7b",
            "7a614e5f584b4859a141665129baa80d",
            "6b9d26d64cce4867a1bf9bc8a26af6de",
            "691b9d74a16f4252a5b28e833e8db32e",
            "13e70ac4032a4b7d99093e5bf05a4701"
          ]
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eca0687499a8454bbaab1ef08848a58e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "SSucUeB4ulB9",
        "outputId": "fadba9dd-222f-4664-f545-93637a1a9d7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table style=\"border:1px solid black\" >\n",
              "  <tr>\n",
              "    <th style=\"text-align: center; border:1px solid black\">PROMPT</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">BEFORE</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">AFTER</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">``</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> 2019-2020 School Year\n",
              "The 20</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">TO BE GENERATED AFTER FINETUNING</pre></td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`import`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">import Foundation\n",
              "\n",
              "public extension NSURL {\n",
              "    public var absoluteString: String {\n",
              "</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">TO BE GENERATED AFTER FINETUNING</pre></td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`from`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">from __future__ import absolute_import\n",
              "from __future__ import division\n",
              "from</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">TO BE GENERATED AFTER FINETUNING</pre></td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`while`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">while(1)\n",
              "while(1) {\n",
              "    // do something\n",
              "}\n",
              "\\</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">TO BE GENERATED AFTER FINETUNING</pre></td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`try`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">try to find the best solution for your needs.\n",
              "We are a team of professionals with</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">TO BE GENERATED AFTER FINETUNING</pre></td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`if`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">if ( !window.atmosphere ) {\n",
              "    window.atmosphere = {};</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">TO BE GENERATED AFTER FINETUNING</pre></td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`for`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">for the 2019-2020 school year.\n",
              "The application process</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">TO BE GENERATED AFTER FINETUNING</pre></td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`torch`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">torchbearer 2017-05-18 19</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">TO BE GENERATED AFTER FINETUNING</pre></td>\n",
              "  </tr>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# This template helps to compare generated code samples in pretty table form\n",
        "# feel free to present your work in other forms\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "table_template = \"\"\"<table style=\"border:1px solid black\" >\n",
        "  <tr>\n",
        "    <th style=\"text-align: center; border:1px solid black\">PROMPT</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">BEFORE</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">AFTER</th>\n",
        "  </tr>\n",
        "{}\n",
        "</table>\"\"\"\n",
        "\n",
        "row_template = '''  <tr>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`{}`</pre></td>\n",
        "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "  </tr>'''\n",
        "\n",
        "rows = []\n",
        "\n",
        "for prompt in prompts:\n",
        "    # replace placeholders in the format() arguments\n",
        "    rows.append(row_template.format(prompt, baseline_outputs[prompt], \"TO BE GENERATED AFTER FINETUNING\"))\n",
        "\n",
        "display(HTML(table_template.format('\\n'.join(rows))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrKidv5KulB9"
      },
      "source": [
        "If you reach this: congratulations! you've completed everything in this practice session.\n",
        "\n",
        "If you want to dig deeper, try to implement prompt-tuning (for bonus points!).\n",
        "You can read more about prompt tuning variants in paper [1](https://arxiv.org/abs/2104.08691) or paper [2](https://arxiv.org/abs/2101.00190). Both versions can be implemented by passing trainable prompts as `model.forward(..., past_key_values=your_prompts)`.\n",
        "\n",
        "\n",
        "\n",
        "### Read more\n",
        "\n",
        "* How post-training quantization works: https://arxiv.org/abs/2208.07339\n",
        "* An overview of running large models: https://huggingface.co/docs/accelerate/package_reference/big_modeling\n",
        "* A general library for different adapter types: https://adapterhub.ml/\n",
        "\n",
        "\n",
        "### [extra info] Running other models.\n",
        "\n",
        "This notebook's code can run with other models of similar size, such as [Falcon-7B](https://huggingface.co/tiiuae/falcon-7b), [OPT-6.7B](https://huggingface.co/facebook/opt-6.7b) or [BLOOM-7.1B](https://huggingface.co/bigscience/bloom-7b1). However, they will require minor code tweaks:\n",
        "1. change the model name in `AutoModelForCausalLM.from_pretrained()` __and__ `AutoTokenizer`\n",
        "2. In the prompt tuning code, change `model.model.embed_tokens` to refer to the target model's word embeddings. Simply `print(model)` to navigate to them.\n",
        "3. Change code to add Lora layers - specifically where you what the transformer block components, since those components now have different names."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a868f8a190f74df2a99a50e2ca9a7cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_895c44b30fd24b8b9bbedc631a7934ec",
              "IPY_MODEL_92f3ee2ed68c4defbed2fe9bef0f20b2",
              "IPY_MODEL_3321598939fd4d76957155f58097fadd"
            ],
            "layout": "IPY_MODEL_f0fe9da3411840ef8d7eff80883cb8e9"
          }
        },
        "895c44b30fd24b8b9bbedc631a7934ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ad2b69a25304e5f903f2fd43b538340",
            "placeholder": "",
            "style": "IPY_MODEL_7aea6cd9a18b4dd9b40bbe65fb0b9069",
            "value": "Map: 100%"
          }
        },
        "92f3ee2ed68c4defbed2fe9bef0f20b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f72b2d490b04440b800ac3c8ab05e625",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6ddf10ea9ef499f917c81fde3e63cd2",
            "value": 32
          }
        },
        "3321598939fd4d76957155f58097fadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31c4ef0dab98410d88891a2c27fdb5c1",
            "placeholder": "",
            "style": "IPY_MODEL_54b23e64bbc444b4abc3f25832e3677d",
            "value": " 32/32 [00:00&lt;00:00, 325.58 examples/s]"
          }
        },
        "f0fe9da3411840ef8d7eff80883cb8e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ad2b69a25304e5f903f2fd43b538340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aea6cd9a18b4dd9b40bbe65fb0b9069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f72b2d490b04440b800ac3c8ab05e625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6ddf10ea9ef499f917c81fde3e63cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31c4ef0dab98410d88891a2c27fdb5c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54b23e64bbc444b4abc3f25832e3677d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44f4fc525a57437b8369fb1dbb4e2c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02fe4cc07f514bd5a1563cefaf686d7e",
              "IPY_MODEL_99018f191ac84dcbbdfdd919949febf3",
              "IPY_MODEL_1d9a9f3bde214dbb9a7cfe03895028ac"
            ],
            "layout": "IPY_MODEL_f775152cc02f4f4aab301dd458867a6a"
          }
        },
        "02fe4cc07f514bd5a1563cefaf686d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7b652f159754e7a9400df40bb0a534a",
            "placeholder": "",
            "style": "IPY_MODEL_eb44f7b01c9146ae842f6d1cd565e2c6",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "99018f191ac84dcbbdfdd919949febf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efd3c38a8d984a15b77ebc1d9c913637",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e111f26efd3405eb52a25a3fb56b0d4",
            "value": 33
          }
        },
        "1d9a9f3bde214dbb9a7cfe03895028ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed464446ced14003b14d7052354c9a74",
            "placeholder": "",
            "style": "IPY_MODEL_0d5b584b3e57454bba7ea7c0eac08b62",
            "value": "33/33[02:08&lt;00:00,4.03s/it]"
          }
        },
        "f775152cc02f4f4aab301dd458867a6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7b652f159754e7a9400df40bb0a534a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb44f7b01c9146ae842f6d1cd565e2c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efd3c38a8d984a15b77ebc1d9c913637": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e111f26efd3405eb52a25a3fb56b0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed464446ced14003b14d7052354c9a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d5b584b3e57454bba7ea7c0eac08b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa3c06be6bdc489fa0a50b567cf68740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc475ef758604545a642af22d3d06eb5",
              "IPY_MODEL_262201e2600247beae2b0c6143df9675",
              "IPY_MODEL_ca4fb6fa87ee4320a9d481a564412981"
            ],
            "layout": "IPY_MODEL_12819f593d7148a4be05fba00d8c5628"
          }
        },
        "fc475ef758604545a642af22d3d06eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc4594eae24f4466b26d0da95117e5e7",
            "placeholder": "",
            "style": "IPY_MODEL_8e107b4363d1497b97190cd57aa6acbc",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "262201e2600247beae2b0c6143df9675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d8c6189943045c4a4b02813dfcc056c",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7fc8eee00694f87b5a5f2823cc91ba7",
            "value": 33
          }
        },
        "ca4fb6fa87ee4320a9d481a564412981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_835f949737564c3f9733db1f9ac80804",
            "placeholder": "",
            "style": "IPY_MODEL_80476ea3a4e44be2aee1e56f6fed76b4",
            "value": "33/33[02:05&lt;00:00,4.21s/it]"
          }
        },
        "12819f593d7148a4be05fba00d8c5628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc4594eae24f4466b26d0da95117e5e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e107b4363d1497b97190cd57aa6acbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d8c6189943045c4a4b02813dfcc056c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7fc8eee00694f87b5a5f2823cc91ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "835f949737564c3f9733db1f9ac80804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80476ea3a4e44be2aee1e56f6fed76b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3780a6287f60449aa35067b4a420b169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c51e32cd43b94e19a8c155e865189ad3",
              "IPY_MODEL_7abf7bd9e6434ebb965b261cff29c9ef",
              "IPY_MODEL_63fa9145a04345d29d467ac805462590"
            ],
            "layout": "IPY_MODEL_fe65403f1518482f9a712065efcaaae3"
          }
        },
        "c51e32cd43b94e19a8c155e865189ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd31d7862f4d48afb98b076161a6c373",
            "placeholder": "",
            "style": "IPY_MODEL_4d944ce779654f67a29815172cb34afe",
            "value": "100%"
          }
        },
        "7abf7bd9e6434ebb965b261cff29c9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cabf59fc6cac45159c34000fcd00e906",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_200cfcf0679d403788f98fb891d33897",
            "value": 8
          }
        },
        "63fa9145a04345d29d467ac805462590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8419fc52ad340f48ad3ccf512d861e1",
            "placeholder": "",
            "style": "IPY_MODEL_47960e499aae47f58630ae05bc66f02b",
            "value": "8/8[03:37&lt;00:00,27.24s/it]"
          }
        },
        "fe65403f1518482f9a712065efcaaae3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd31d7862f4d48afb98b076161a6c373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d944ce779654f67a29815172cb34afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cabf59fc6cac45159c34000fcd00e906": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "200cfcf0679d403788f98fb891d33897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8419fc52ad340f48ad3ccf512d861e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47960e499aae47f58630ae05bc66f02b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eca0687499a8454bbaab1ef08848a58e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bb9a13a2d684676bec9a9cdd4c24826",
              "IPY_MODEL_29f99ebcc6b346cdb3def457cbe21642",
              "IPY_MODEL_6a340d18f76f42a58bde0bd5cd3d6470"
            ],
            "layout": "IPY_MODEL_eaa38931237e407a85160dc37daeb262"
          }
        },
        "3bb9a13a2d684676bec9a9cdd4c24826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4e7a3d488a94367be197f68a6a05fa7",
            "placeholder": "",
            "style": "IPY_MODEL_bef04e104a2942748414bd1aa9328b7b",
            "value": "100%"
          }
        },
        "29f99ebcc6b346cdb3def457cbe21642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a614e5f584b4859a141665129baa80d",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b9d26d64cce4867a1bf9bc8a26af6de",
            "value": 8
          }
        },
        "6a340d18f76f42a58bde0bd5cd3d6470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_691b9d74a16f4252a5b28e833e8db32e",
            "placeholder": "",
            "style": "IPY_MODEL_13e70ac4032a4b7d99093e5bf05a4701",
            "value": "8/8[00:18&lt;00:00,2.00s/it]"
          }
        },
        "eaa38931237e407a85160dc37daeb262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4e7a3d488a94367be197f68a6a05fa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bef04e104a2942748414bd1aa9328b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a614e5f584b4859a141665129baa80d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b9d26d64cce4867a1bf9bc8a26af6de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "691b9d74a16f4252a5b28e833e8db32e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13e70ac4032a4b7d99093e5bf05a4701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}