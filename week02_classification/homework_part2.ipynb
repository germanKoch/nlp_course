{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary prediction, episode II: make it actually work (4 points)\n",
    "\n",
    "Your main task is to use some of the tricks you've learned on the network and analyze if you can improve __validation MAE__. Try __at least 3 options__ from the list below for a passing grade. Write a short report about what you have tried. More ideas = more bonus points. \n",
    "\n",
    "__Please be serious:__ \" plot learning curves in MAE/epoch, compare models based on optimal performance, test one change at a time. You know the drill :)\n",
    "\n",
    "You can use either __pytorch__ or __tensorflow__ or any other framework (e.g. pure __keras__). Feel free to adapt the seminar code for your needs. For tensorflow version, consider `seminar_tf2.ipynb` as a starting point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK, PAD = \"UNK\", \"PAD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244768, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Train_rev1.zip\", compression='zip', index_col=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "TARGET_COLUMN = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def tokenize(text):\n",
    "    if not text or pd.isna(text):\n",
    "        return ''\n",
    "    tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "    try:\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "    except:\n",
    "        print(text)\n",
    "    return ' '.join(tokens).lower()\n",
    "\n",
    "\n",
    "data['FullDescription'] = data['FullDescription'].apply(tokenize)\n",
    "data['Title'] = data['Title'].apply(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "token_counts = Counter()\n",
    "\n",
    "for desc in data[\"FullDescription\"]:\n",
    "    for token in desc.split():\n",
    "        token_counts[token] += 1\n",
    "for desc in data[\"Title\"]:\n",
    "    for token in desc.split():\n",
    "        token_counts[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = sorted(t for t, c in token_counts.items() if c >= min_count)#TODO<YOUR CODE HERE>\n",
    "\n",
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_id = {token: idx for idx, token in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None, min_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "\n",
    "    if min_len is not None and min_len > max_len:\n",
    "        max_len = min_len\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  195814\n",
      "Validation size =  48954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def to_tensors(batch, device):\n",
    "    batch_tensors = dict()\n",
    "    for key, arr in batch.items():\n",
    "        if key in [\"FullDescription\", \"Title\"]:\n",
    "            batch_tensors[key] = torch.tensor(arr, device=device, dtype=torch.int64)\n",
    "        else:\n",
    "            batch_tensors[key] = torch.tensor(arr, device=device)\n",
    "    return batch_tensors\n",
    "\n",
    "\n",
    "def make_batch(data, max_len=None, min_len=None, word_dropout=0, device=device):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len, min_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len, min_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if TARGET_COLUMN in data.columns:\n",
    "        batch[TARGET_COLUMN] = data[TARGET_COLUMN].values\n",
    "    \n",
    "    return to_tensors(batch, device)\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, device=device, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], device=device, **kwargs)\n",
    "            yield batch\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(model, data, batch_size, name=\"\", device=torch.device('cpu'), **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterate_minibatches(data, batch_size=batch_size, shuffle=False, device=device, **kw):\n",
    "            batch_pred = model(batch)\n",
    "            squared_error += torch.sum(torch.square(batch_pred - batch[TARGET_COLUMN]))\n",
    "            abs_error += torch.sum(torch.abs(batch_pred - batch[TARGET_COLUMN]))\n",
    "            num_samples += len(batch_pred)\n",
    "    mse = squared_error.detach().cpu().numpy() / num_samples\n",
    "    mae = abs_error.detach().cpu().numpy() / num_samples\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % mse)\n",
    "    print(\"Mean absolute error: %.5f\" % mae)\n",
    "    return mse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train(epochs, model, batch_size, data_train, data_val):\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"epoch: {epoch}\")\n",
    "        model.train()\n",
    "        for i, batch in tqdm(enumerate(\n",
    "                iterate_minibatches(data_train, batch_size=batch_size, device=device)),\n",
    "                total=len(data_train) // batch_size\n",
    "            ):\n",
    "            pred = model(batch)\n",
    "            loss = criterion(pred, batch[TARGET_COLUMN])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print_metrics(model, data_val, batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_number(model):\n",
    "    params_num = 0\n",
    "\n",
    "    for parameter in model.parameters():\n",
    "        params_num += np.prod(parameter.size())\n",
    "\n",
    "    return params_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A short report\n",
    "\n",
    "Please tell us what you did and how did it work.\n",
    "\n",
    "`<YOUR_TEXT_HERE>`, i guess..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended options\n",
    "\n",
    "#### A) CNN architecture\n",
    "\n",
    "All the tricks you know about dense and convolutional neural networks apply here as well.\n",
    "* Dropout. Nuff said.\n",
    "* Batch Norm. This time it's `nn.BatchNorm*`/`L.BatchNormalization`\n",
    "* Parallel convolution layers. The idea is that you apply several nn.Conv1d to the same embeddings and concatenate output channels.\n",
    "* More layers, more neurons, ya know...\n",
    "\n",
    "\n",
    "#### B) Play with pooling\n",
    "\n",
    "There's more than one way to perform pooling:\n",
    "* Max over time (independently for each feature)\n",
    "* Average over time (excluding PAD)\n",
    "* Softmax-pooling:\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot {{e ^ {h_{i, t}}} \\over \\sum_\\tau e ^ {h_{j, \\tau}} } }$$\n",
    "\n",
    "* Attentive pooling\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot Attn(h_t)}$$\n",
    "\n",
    ", where $$ Attn(h_t) = {{e ^ {NN_{attn}(h_t)}} \\over \\sum_\\tau e ^ {NN_{attn}(h_\\tau)}}  $$\n",
    "and $NN_{attn}$ is a dense layer.\n",
    "\n",
    "The optimal score is usually achieved by concatenating several different poolings, including several attentive pooling with different $NN_{attn}$ (aka multi-headed attention).\n",
    "\n",
    "The catch is that keras layers do not inlude those toys. You will have to [write your own keras layer](https://keras.io/layers/writing-your-own-keras-layers/). Or use pure tensorflow, it might even be easier :)\n",
    "\n",
    "#### C) Fun with words\n",
    "\n",
    "It's not always a good idea to train embeddings from scratch. Here's a few tricks:\n",
    "\n",
    "* Use a pre-trained embeddings from `gensim.downloader.load`. See last lecture.\n",
    "* Start with pre-trained embeddings, then fine-tune them with gradient descent. You may or may not download pre-trained embeddings from [here](http://nlp.stanford.edu/data/glove.6B.zip) and follow this [manual](https://keras.io/examples/nlp/pretrained_word_embeddings/) to initialize your Keras embedding layer with downloaded weights.\n",
    "* Use the same embedding matrix in title and desc vectorizer\n",
    "\n",
    "\n",
    "#### D) Going recurrent\n",
    "\n",
    "We've already learned that recurrent networks can do cool stuff in sequence modelling. Turns out, they're not useless for classification as well. With some tricks of course..\n",
    "\n",
    "* Like convolutional layers, LSTM should be pooled into a fixed-size vector with some of the poolings.\n",
    "* Since you know all the text in advance, use bidirectional RNN\n",
    "  * Run one LSTM from left to right\n",
    "  * Run another in parallel from right to left \n",
    "  * Concatenate their output sequences along unit axis (dim=-1)\n",
    "\n",
    "* It might be good idea to mix convolutions and recurrent layers differently for title and description\n",
    "\n",
    "\n",
    "#### E) Optimizing seriously\n",
    "\n",
    "* You don't necessarily need 100 epochs. Use early stopping. If you've never done this before, take a look at [early stopping callback(keras)](https://keras.io/callbacks/#earlystopping) or in [pytorch(lightning)](https://pytorch-lightning.readthedocs.io/en/latest/common/early_stopping.html).\n",
    "  * In short, train until you notice that validation\n",
    "  * Maintain the best-on-validation snapshot via `model.save(file_name)`\n",
    "  * Plotting learning curves is usually a good idea\n",
    "  \n",
    "Good luck! And may the force be with you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = make_batch(data_train[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Cnn arhictecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import embbedding\n",
    "from torch.nn import Embedding\n",
    "from torch.nn import Conv1d\n",
    "from torch.nn import BatchNorm1d\n",
    "from torch.nn import Dropout\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "\n",
    "class WordEmbedding(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), embed_size=50) -> None:\n",
    "        super().__init__()\n",
    "        self.embed = Embedding(n_tokens, embed_size)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.embed(batch)\n",
    "\n",
    "class TitleEncoder(nn.Module):\n",
    "    def __init__(self, embed: WordEmbedding, embed_size=50, encoding_dim=32) -> None:\n",
    "        super().__init__()\n",
    "        self.embed = embed\n",
    "        self.conv1 = Conv1d(in_channels=embed_size, out_channels=encoding_dim, kernel_size=3)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        batch = self.embed(batch)\n",
    "        batch = self.conv1(batch.permute(0, 2, 1))\n",
    "        return torch.max(batch, dim=2).values\n",
    "\n",
    "class DescriptionEncoder(nn.Module):\n",
    "    def __init__(self, embed: WordEmbedding, embed_size=50, encoding_dim=32) -> None:\n",
    "        super().__init__()\n",
    "        self.embed = embed\n",
    "        self.conv1 = Conv1d(in_channels=embed_size, out_channels=encoding_dim, kernel_size=3)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        batch = self.embed(batch)\n",
    "        batch = self.conv1(batch.permute(0, 2, 1))\n",
    "        return torch.max(batch, dim=2).values\n",
    "    \n",
    "class CetegoricalEncoder(nn.Module):\n",
    "    def __init__(self, n_cat_features, encoding_dim=64) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = Linear(in_features=n_cat_features, out_features=encoding_dim)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        return self.linear(batch)\n",
    "\n",
    "\n",
    "class SalaryPredictor(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), \n",
    "                word_embed_size=50, \n",
    "                hidden_dim=32, \n",
    "                title_encoding_dim=32, \n",
    "                description_encoding_dim=32,\n",
    "                cat_encoding_dim=32,\n",
    "                dropout=0.1,\n",
    "                n_cat_features=len(categorical_vectorizer.vocabulary_)):\n",
    "        super().__init__()\n",
    "        self.embed = WordEmbedding(n_tokens, word_embed_size)\n",
    "        self.title_encoder = TitleEncoder(self.embed, word_embed_size, title_encoding_dim)\n",
    "        self.description_encoder = DescriptionEncoder(self.embed, word_embed_size, description_encoding_dim)\n",
    "        self.categorical_encoder = CetegoricalEncoder(n_cat_features, cat_encoding_dim)\n",
    "        self.relu1 = ReLU()\n",
    "        self.normalization = BatchNorm1d(title_encoding_dim + description_encoding_dim + cat_encoding_dim)\n",
    "        self.linear = Linear(\n",
    "            in_features=title_encoding_dim + description_encoding_dim + cat_encoding_dim, \n",
    "            out_features=hidden_dim\n",
    "        )\n",
    "        self.relu2 = ReLU()\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.out = Linear(in_features=hidden_dim, out_features=1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        title_encoding = self.title_encoder(batch['Title'])\n",
    "        description_encoding = self.description_encoder(batch['FullDescription'])\n",
    "        category_encoding = self.categorical_encoder(batch['Categorical'])\n",
    "        full_encoding = torch.cat([title_encoding, description_encoding, category_encoding], dim=1)\n",
    "        full_encoding = self.normalization(self.relu1(full_encoding))\n",
    "        full_encoding = self.relu2(self.linear(full_encoding))\n",
    "        full_encoding = self.dropout(full_encoding)\n",
    "        return self.out(full_encoding).squeeze(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SalaryPredictor(dropout=0.4, hidden_dim=64, description_encoding_dim=64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters: 1851581\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of parameters:\", get_params_number(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0984fb9f6d2a480bad495e1c67290fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.13340\n",
      "Mean absolute error: 0.28107\n",
      "epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb7c86415004265a49cea0da4c67920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.12495\n",
      "Mean absolute error: 0.26992\n",
      "epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0f7bb0c3144682aecd2e3587df3dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.10835\n",
      "Mean absolute error: 0.25048\n",
      "epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff7d569bb794433b75858b758c98b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.10460\n",
      "Mean absolute error: 0.24603\n",
      "epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5f099233784de3a5701e4844d5a81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.10506\n",
      "Mean absolute error: 0.24545\n"
     ]
    }
   ],
   "source": [
    "train(5, model, 16, data_train, data_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Recurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import embbedding\n",
    "from torch.nn import Embedding\n",
    "from torch.nn import LSTM\n",
    "from torch.nn import BatchNorm1d\n",
    "from torch.nn import Dropout\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "\n",
    "class WordEmbedding(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), embed_size=50) -> None:\n",
    "        super().__init__()\n",
    "        self.embed = Embedding(n_tokens, embed_size)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.embed(batch)\n",
    "\n",
    "class TitleEncoder(nn.Module):\n",
    "    def __init__(self, embed: WordEmbedding, embed_size=50, encoding_dim=32, dropout=0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.embed = embed\n",
    "        self.lstm = LSTM(\n",
    "            dropout=dropout,\n",
    "            input_size=embed_size, \n",
    "            hidden_size=encoding_dim, \n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        batch = self.embed(batch)\n",
    "        output, (hidden, cell) = self.lstm(batch)\n",
    "        return torch.cat([hidden[0], hidden[1]], dim=1)\n",
    "\n",
    "class DescriptionEncoder(nn.Module):\n",
    "    def __init__(self, embed: WordEmbedding, embed_size=50, encoding_dim=32, dropout=0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.embed = embed\n",
    "        self.lstm = LSTM(\n",
    "            dropout=dropout,\n",
    "            input_size=embed_size, \n",
    "            hidden_size=encoding_dim, \n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        batch = self.embed(batch)\n",
    "        output, (hidden, cell) = self.lstm(batch)\n",
    "        return torch.cat([hidden[0], hidden[1]], dim=1)\n",
    "    \n",
    "class CetegoricalEncoder(nn.Module):\n",
    "    def __init__(self, n_cat_features, encoding_dim=64) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = Linear(in_features=n_cat_features, out_features=encoding_dim)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        return self.linear(batch)\n",
    "\n",
    "\n",
    "class SalaryPredictor(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), \n",
    "                word_embed_size=50, \n",
    "                hidden_dim=32, \n",
    "                title_encoding_dim=32, \n",
    "                description_encoding_dim=32,\n",
    "                cat_encoding_dim=32,\n",
    "                dropout=0.1,\n",
    "                n_cat_features=len(categorical_vectorizer.vocabulary_)):\n",
    "        super().__init__()\n",
    "        self.embed = WordEmbedding(n_tokens, word_embed_size)\n",
    "        self.title_encoder = TitleEncoder(self.embed, word_embed_size, title_encoding_dim, dropout)\n",
    "        self.description_encoder = DescriptionEncoder(self.embed, word_embed_size, description_encoding_dim, dropout)\n",
    "        self.categorical_encoder = CetegoricalEncoder(n_cat_features, cat_encoding_dim)\n",
    "        self.relu1 = ReLU()\n",
    "        self.normalization = BatchNorm1d(title_encoding_dim*2 + description_encoding_dim*2 + cat_encoding_dim)\n",
    "        self.linear = Linear(\n",
    "            in_features=title_encoding_dim*2 + description_encoding_dim*2 + cat_encoding_dim, \n",
    "            out_features=hidden_dim\n",
    "        )\n",
    "        self.relu2 = ReLU()\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.out = Linear(in_features=hidden_dim, out_features=1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        title_encoding = self.title_encoder(batch['Title'])\n",
    "        description_encoding = self.description_encoder(batch['FullDescription'])\n",
    "        category_encoding = self.categorical_encoder(batch['Categorical'])\n",
    "        full_encoding = torch.cat([title_encoding, description_encoding, category_encoding], dim=1)\n",
    "        full_encoding = self.normalization(self.relu1(full_encoding))\n",
    "        full_encoding = self.relu2(self.linear(full_encoding))\n",
    "        full_encoding = self.dropout(full_encoding)\n",
    "        return self.out(full_encoding).squeeze(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model = SalaryPredictor(\n",
    "    dropout=0.4, \n",
    "    hidden_dim=64, \n",
    "    description_encoding_dim=128,  \n",
    "    title_encoding_dim=64,\n",
    "    cat_encoding_dim=32\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters: 2099805\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of parameters:\", get_params_number(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64dbc4028e3c493494d451bc1d1c3b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.19278\n",
      "Mean absolute error: 0.32592\n",
      "epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4405bd8fc974f158ea1ffc6119a19dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs, model, batch_size, data_train, data_val)\u001b[0m\n\u001b[0;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(pred, batch[TARGET_COLUMN])\n\u001b[0;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     20\u001b[0m print_metrics(model, data_val, batch_size, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32md:\\python310\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\python310\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(5, model, 16, data_train, data_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pooling with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import embbedding\n",
    "from torch.nn import Embedding\n",
    "from torch.nn import Conv1d\n",
    "from torch.nn import BatchNorm1d\n",
    "from torch.nn import Dropout\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.linear = Linear(in_features=in_features, out_features=1)\n",
    "        self.relu = ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        attent_score = self.linear(batch).squeeze(2)\n",
    "        attent_score = self.relu(batch)\n",
    "        attent_score = self.softmax(batch)\n",
    "        return torch.sum(batch * attent_score, dim=1)\n",
    "\n",
    "class WordEmbedding(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), embed_size=50) -> None:\n",
    "        super().__init__()\n",
    "        self.embed = Embedding(n_tokens, embed_size)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.embed(batch)\n",
    "\n",
    "class TitleEncoder(nn.Module):\n",
    "    def __init__(self, embed: WordEmbedding, embed_size=50, encoding_dim=32) -> None:\n",
    "        super().__init__()\n",
    "        self.embed = embed\n",
    "        self.conv1 = Conv1d(in_channels=embed_size, out_channels=encoding_dim, kernel_size=3)\n",
    "        self.attention1 = AttentionPooling(in_features=encoding_dim)\n",
    "        self.attention2 = AttentionPooling(in_features=encoding_dim)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        batch = self.embed(batch)\n",
    "        batch = self.conv1(batch.permute(0, 2, 1))\n",
    "        batch = batch.permute(0, 2, 1)\n",
    "\n",
    "        attention_1 = self.attention1(batch)\n",
    "        attention_2 = self.attention2(batch)\n",
    "\n",
    "        return torch.cat([attention_1, attention_2], dim=1)\n",
    "\n",
    "class DescriptionEncoder(nn.Module):\n",
    "    def __init__(self, embed: WordEmbedding, embed_size=50, encoding_dim=32) -> None:\n",
    "        super().__init__()\n",
    "        self.embed = embed\n",
    "        self.conv1 = Conv1d(in_channels=embed_size, out_channels=encoding_dim, kernel_size=3)\n",
    "        self.attention1 = AttentionPooling(in_features=encoding_dim)\n",
    "        self.attention2 = AttentionPooling(in_features=encoding_dim)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        batch = self.embed(batch)\n",
    "        batch = self.conv1(batch.permute(0, 2, 1))\n",
    "        batch = batch.permute(0, 2, 1)\n",
    "\n",
    "        attention_1 = self.attention1(batch)\n",
    "        attention_2 = self.attention2(batch)\n",
    "\n",
    "        return torch.cat([attention_1, attention_2], dim=1)\n",
    "    \n",
    "class CetegoricalEncoder(nn.Module):\n",
    "    def __init__(self, n_cat_features, encoding_dim=64) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = Linear(in_features=n_cat_features, out_features=encoding_dim)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        batch = self.linear(batch)\n",
    "        return batch\n",
    "\n",
    "\n",
    "class SalaryPredictor(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), \n",
    "                word_embed_size=50, \n",
    "                hidden_dim=32, \n",
    "                title_encoding_dim=32, \n",
    "                description_encoding_dim=32,\n",
    "                cat_encoding_dim=32,\n",
    "                dropout=0.1,\n",
    "                n_cat_features=len(categorical_vectorizer.vocabulary_)):\n",
    "        super().__init__()\n",
    "        self.embed = WordEmbedding(n_tokens, word_embed_size)\n",
    "        self.title_encoder = TitleEncoder(self.embed, word_embed_size, title_encoding_dim)\n",
    "        self.description_encoder = DescriptionEncoder(self.embed, word_embed_size, description_encoding_dim)\n",
    "        self.categorical_encoder = CetegoricalEncoder(n_cat_features, cat_encoding_dim)\n",
    "        self.relu1 = ReLU()\n",
    "        self.normalization = BatchNorm1d(title_encoding_dim*2 + description_encoding_dim*2 + cat_encoding_dim)\n",
    "        self.linear = Linear(\n",
    "            in_features=title_encoding_dim*2 + description_encoding_dim*2 + cat_encoding_dim, \n",
    "            out_features=hidden_dim\n",
    "        )\n",
    "        self.relu2 = ReLU()\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.out = Linear(in_features=hidden_dim, out_features=1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        title_encoding = self.title_encoder(batch['Title'])\n",
    "        description_encoding = self.description_encoder(batch['FullDescription'])\n",
    "        category_encoding = self.categorical_encoder(batch['Categorical'])\n",
    "        full_encoding = torch.cat([title_encoding, description_encoding, category_encoding], dim=1)\n",
    "        full_encoding = self.normalization(self.relu1(full_encoding))\n",
    "        full_encoding = self.relu2(self.linear(full_encoding))\n",
    "        full_encoding = self.dropout(full_encoding)\n",
    "        return self.out(full_encoding).squeeze(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SalaryPredictor(dropout=0.4, hidden_dim=64, description_encoding_dim=64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters: 1858113\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of parameters:\", get_params_number(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99852c16b214386a0c9b666b2515d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.12346\n",
      "Mean absolute error: 0.27296\n"
     ]
    }
   ],
   "source": [
    "train(1, model, 16, data_train, data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
